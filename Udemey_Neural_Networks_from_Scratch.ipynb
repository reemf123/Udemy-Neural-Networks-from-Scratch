{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reemf123/Udemy-Neural-Networks-from-Scratch/blob/main/Udemey_Neural_Networks_from_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Om6KfLECjJ-e"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**General Algorithm**\n",
        "\n",
        "1) Initialize Weights\n",
        "\n",
        "2) Calculate Outputs (summation & sigmoid function output)\n",
        "\n",
        "3) Calculate the error (Cost/Loss Function)\n",
        "\n",
        "4) Calculate the new weights\n",
        "\n",
        "5) Update the weights\n",
        "\n",
        "6) Check if the number of epochs have been reached\n",
        "\n",
        "  - If the number of epochs has not been reached, return to Step 2."
      ],
      "metadata": {
        "id": "FrnNvhtj3X8o"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEG7quTlmp71"
      },
      "source": [
        "**Sigmoid Function**:\n",
        "- when x is small and negative, function approaches 0\n",
        "- when x is big and positive, function approaches 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "oMekUXljm6kl"
      },
      "outputs": [],
      "source": [
        "# Activation Function\n",
        "# Can't use step function for more complex systems\n",
        "def sigmoid(sum):\n",
        "  return (1) / (1 + np.exp(-sum))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvMX0FFewOTT"
      },
      "source": [
        "Activation function gets applied onto the summations at each level\n",
        "\n",
        "**Order of Operations**:\n",
        "\n",
        "1) Multiply inputs by weights product\n",
        "\n",
        "2) Sum each product\n",
        "\n",
        "3) Apply activation function to product\n",
        "\n",
        "4) Repeat Steps 1 - 3 for the next layer until you reach the output.\n",
        "\n",
        "5) Remeber, the output should equal the output of the activation function when the final sum is inputted.\n",
        "\n",
        "6) Use the truths and the final output to compute the loss function (error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aue1O9Znajh"
      },
      "source": [
        "**Goal: Find relationship between inputs and output of XOR Gate.**\n",
        "\n",
        "\n",
        "Inputs:                 \n",
        "0, 0                   \n",
        "0, 1                   \n",
        "1, 0                   \n",
        "1, 1\n",
        "\n",
        "Outputs:\n",
        "0\n",
        "1\n",
        "1\n",
        "0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0er5Glmn9EN"
      },
      "source": [
        "Feed Forward:\n",
        "- data flows from left to right through hidden layer\n",
        "- input layer --> hidden layer --> output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE9acGUkwhqf"
      },
      "source": [
        "Example: Think of learning the outputs to a logical gate with 2 inputs either 0 or 1\n",
        "\n",
        "Layer 1 Calculations:\n",
        "\n",
        "At each layer the activation function is applied to dictate the value of the neuron in the feed forward system.\n",
        "\n",
        "**Summations below represent the values of the 3 hidden neurons in the second layer**\n",
        "\n",
        "(Repeat sum_n calculations for the potential input pairs)\n",
        "\n",
        "sum1 = input_1_1 * weight1[0] + input_1_2 * weight2[0]\n",
        "\n",
        "  Neuron 1 = activation(sum1)\n",
        "\n",
        "sum2 = input_1_1 * weight1[1] + input_1_2 * weight2[1]\n",
        "  Neuron 2 = activation(sum2)\n",
        "\n",
        "sum3 = input_1_1 * weight1[2] + input_1_2 * weight2[2]\n",
        "  Neuronn 3 = activation(sum3)\n",
        "\n",
        "Layer 2 Calculations:\n",
        "\n",
        "final_sum = sum1 * w1 + sum2 * w2 + sum3 * w3\n",
        "  Output Neuron = activation(final_sum)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "xxtXMvfOx_fk"
      },
      "outputs": [],
      "source": [
        "def get_hidden_layer_neurons(input_pairs, input_weights_1, input_weights_2):\n",
        "  input_to_hidden_layer_dic = {}\n",
        "  for i in range(len(input_pairs)):\n",
        "    #print(\"Input:\", input_pairs[i])\n",
        "    sums = np.array([])\n",
        "    activated_neurons = np.array([])\n",
        "    for j in range(len(input_weights_1)):\n",
        "      sum = (input_pairs[i][0] * input_weights_1[j]) + (input_pairs[i][1] * input_weights_2[j])\n",
        "      sums = np.append(sums, sum)\n",
        "      activation_i = sigmoid(sum)\n",
        "      activated_neurons = np.append(activated_neurons, activation_i)\n",
        "\n",
        "    #print(\"Sums: \", sums)\n",
        "    #print(\"Activted Neurons: \", activated_neurons)\n",
        "    #print()\n",
        "    input_to_hidden_layer_dic[i] = activated_neurons\n",
        "  return input_to_hidden_layer_dic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIzO26jw1Wv1",
        "outputId": "471ee532-cba6-4382-9f2d-0e8d3c88b9aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "{0: array([0.5, 0.5, 0.5]), 1: array([0.5885562 , 0.35962319, 0.38485296]), 2: array([0.39555998, 0.32300414, 0.27667802]), 3: array([0.48350599, 0.21131785, 0.19309868])}\n"
          ]
        }
      ],
      "source": [
        "# Weights from input to hidden layer of neurons\n",
        "input_weights_1_1 = np.array([-0.424, -0.740, -0.961])\n",
        "input_weights_2_1 = np.array([0.358, -0.577, -0.469])\n",
        "\n",
        "# Weights from hidden layer of neurons to output\n",
        "output_weights = np.array([-0.017, -0.893, 0.148])\n",
        "\n",
        "input_pairs = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
        "output = np.array([0, 1, 1, 0])\n",
        "\n",
        "input_1 = np.array([0, 0, 1, 1])\n",
        "input_2 = np.array([0, 1, 0, 1])\n",
        "\n",
        "input_to_hidden_layer_dic = get_hidden_layer_neurons(input_pairs, input_weights_1_1, input_weights_2_1)\n",
        "print()\n",
        "print(input_to_hidden_layer_dic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "FyoyXu2WErzq"
      },
      "outputs": [],
      "source": [
        "def get_nn_output(input_pairs, input_to_hidden_layer_dic, output_weights):\n",
        "  sums = np.array([])\n",
        "  activations = np.array([])\n",
        "  for key in range(len(input_to_hidden_layer_dic)): # Key represents the index of the inputs pairs array\n",
        "      input_pair = input_pairs[key]\n",
        "      hidden_layer_neurons = input_to_hidden_layer_dic[key]\n",
        "      sum_input = 0\n",
        "      for i in range(len(hidden_layer_neurons)):\n",
        "        sum_input += ((hidden_layer_neurons[i])*(output_weights[i]))\n",
        "\n",
        "      sums = np.append(sums, sum_input)\n",
        "      activation = sigmoid(sum_input)\n",
        "      activations = np.append(activations, activation)\n",
        "      print(\"Input Pair:\", input_pair, \"Output Neuron Summation:\", round(sum_input, 3), \"Output Neuron Activation: \", round(activation, 3))\n",
        "\n",
        "  return activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lPTwc65GeKJ",
        "outputId": "5d1a68a8-f94e-413e-826e-5e5fae9e7ba8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Pair: [0 0] Output Neuron Summation: -0.381 Output Neuron Activation:  0.406\n",
            "Input Pair: [0 1] Output Neuron Summation: -0.274 Output Neuron Activation:  0.432\n",
            "Input Pair: [1 0] Output Neuron Summation: -0.254 Output Neuron Activation:  0.437\n",
            "Input Pair: [1 1] Output Neuron Summation: -0.168 Output Neuron Activation:  0.458\n"
          ]
        }
      ],
      "source": [
        "activations = get_nn_output(input_pairs, input_to_hidden_layer_dic, output_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRKO2BzdPw4S"
      },
      "source": [
        "Upon each layer within the neural network, a summation of weights and activation function must be applied.\n",
        "\n",
        "The output neuron activation is the final result of the neural network. The output neuron activation is what must be compared with the intended output (the truth)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5osD02lQf2e"
      },
      "source": [
        "**Error - Loss Function**\n",
        "\n",
        "Compare the predictions of the neural network with the expected output from the data set\n",
        "\n",
        "Simplest Calculation for error: correct - prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "OoXaBU9CQ9vK"
      },
      "outputs": [],
      "source": [
        "def calculate_error(truth: np.array, predictions: np.array) -> np.array:\n",
        "  error = truth - predictions\n",
        "  return error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def average_error(error:np.array):\n",
        "  return np.mean(abs(error))"
      ],
      "metadata": {
        "id": "F4-Uc2am0ouj"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "x_R1w_zSCE08"
      },
      "outputs": [],
      "source": [
        "# Number of times weights will get updated\n",
        "# Number of times the steps of the general algorithm is run\n",
        "epochs = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "GeLhLnE2Q_uL"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement Partial Derivavtive Formula to indicate in which direction the weights should be function\n",
        "# d = y * (1 - y) where y is the value of the sigmoid/activation function\n",
        "def sigmoid_deriviative(y):\n",
        "  return (y *(1 - y))"
      ],
      "metadata": {
        "id": "sp78JDPu5yuH"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(sigmoid_deriviative(activations))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-i137NeO6n2R",
        "outputId": "75019c6e-b648-4324-d37e-edff684c572b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([0.2411425 , 0.24535947, 0.24600391, 0.24823702])"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Procedure for updating weights:**\n",
        "\n",
        "1) Compute Activation Function (Sigmoid Function)\n",
        "\n",
        "2) Compute Partial Derivavtive (Deriviative of Sigmoid Function)\n",
        "\n",
        "3) Compute Delta: delta = error * derivavtive of sigmoid\n",
        "\n",
        "4) Compute Gradient"
      ],
      "metadata": {
        "id": "eUenje1n68XW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradient(truth, predictions):\n",
        "  error = calculate_error(truth, predictions)\n",
        "  derivatives = sigmoid_deriviative(predictions)\n",
        "  delta = error * derivatives\n",
        "  return delta"
      ],
      "metadata": {
        "id": "FxX3x6zW7mYp"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delta_output = compute_gradient(output, activations)\n",
        "display(delta_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TrA1-UVp97Np",
        "outputId": "22c57375-46ad-4b43-c393-032751b61bc7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([-0.0978763 ,  0.13939397,  0.138553  , -0.11369557])"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now you need to back propagate to the hidden layer**"
      ],
      "metadata": {
        "id": "Uu_8Zm05AO0_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$delta_{hidden layer}$ = $sigmoid_{derivavtive}$ * weight * $delta_{output}$\n",
        "\n",
        "In this calculation, the weight is the set of weights that connect the hidden layer to the output (i.e variable output_weights)"
      ],
      "metadata": {
        "id": "fzjMppkjAceH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Input = (0, 0) Ouput = (0.00, 0.021, -0.003)\n",
        "def compute_hidden_layer_delta(output_weights, delta_outputs, input_to_hidden_layer_dic):\n",
        "  delta_hidden_layers = np.array([])\n",
        "  for i in range(len(input_pairs)):\n",
        "    delta_output = delta_outputs[i]\n",
        "    delta_hidden_layer = np.array([])\n",
        "    for j in range(len(output_weights)):\n",
        "      # Apply for each instance of input\n",
        "      # update with proper input to sigmoid_derivative function\n",
        "      delta_hidden = sigmoid_deriviative(input_to_hidden_layer_dic[i][j]) * output_weights[j] * delta_output\n",
        "      delta_hidden_layer = np.append(delta_hidden_layer, delta_hidden)\n",
        "\n",
        "    if delta_hidden_layers.size == 0:\n",
        "        delta_hidden_layers = np.array([delta_hidden_layer])\n",
        "    else:\n",
        "      delta_hidden_layers = np.append(delta_hidden_layers, [delta_hidden_layer], axis=0)\n",
        "\n",
        "  return delta_hidden_layers"
      ],
      "metadata": {
        "id": "n8BDtAlWAUIw"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_hidden_layer_delta(output_weights, delta_output, input_to_hidden_layer_dic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94iHihOxDHgA",
        "outputId": "ee40f4b5-7dd6-41d7-ebf0-afb8094ea1bd"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.00041597,  0.02185088, -0.00362142],\n",
              "       [-0.00057384, -0.02866677,  0.00488404],\n",
              "       [-0.00056316, -0.02705587,  0.00410378],\n",
              "       [ 0.00048268,  0.01692128, -0.00262183]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How to perform weight update**"
      ],
      "metadata": {
        "id": "Xz4cvzxQR3EZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Backpropagate: Propagate weights from output layer to input layer\n",
        "\n",
        "$weight_{n+1}$ = $weight_{n}$ + ($input * delta * learning rate$)"
      ],
      "metadata": {
        "id": "F_6fe8BhR6l6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Learning Rate: How fast the algorithm will run**\n",
        "\n",
        "Fast Learning Rate: fast convergence but may lose the global minimum"
      ],
      "metadata": {
        "id": "3NDbSkQ8S5RH"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqGGQJEV9NqDQ8SIcaDbJG",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}